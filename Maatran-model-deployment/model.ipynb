{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>The following Notebook defines the model used for pregnancy risk classification</h3>\n",
        "<p> This file should only be used for experimental or referential purposes, and not for updating the model deployed </p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qnRiN2RuEVJ_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xkut8JiRFJZi"
      },
      "outputs": [],
      "source": [
        "# Load the dataset from a CSV file\n",
        "data = pd.read_csv('Maternal Health Risk Data Set.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "61beLaGxFtQb"
      },
      "outputs": [],
      "source": [
        "# Check for missing or invalid data and handle it appropriately\n",
        "data.dropna(inplace=True)\n",
        "if any(data.isnull().any()):\n",
        "  raise ValueError('Invalid data detected')\n",
        "\n",
        "# Split the data into feature columns and the target column\n",
        "X = data[['Age', 'SystolicBP', 'DiastolicBP', 'BS', 'BodyTemp', 'HeartRate']]\n",
        "y = data['RiskLevel']\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Check for imbalanced data and balance it using oversampling or undersampling\n",
        "if len(y[y == 'high risk']) / len(y) < 0.1:\n",
        "  # Use oversampling to balance the data\n",
        "  from imblearn.over_sampling import SMOTE\n",
        "  smote = SMOTE(random_state=0)\n",
        "  X_resampled, y_resampled = smote.fit_sample(X, y)\n",
        "else:\n",
        "  # Use undersampling to balance the data\n",
        "  from imblearn.under_sampling import RandomUnderSampler\n",
        "  rus = RandomUnderSampler(random_state=0)\n",
        "  X_resampled, y_resampled = rus.fit_resample(X, y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-0.36173812  1.45702716  1.6960543  -0.25091417 -0.4852155   0.70481475]\n",
            " [-0.65874416  0.36976548  0.25502279 -0.55468943 -0.4852155   0.21005383]\n",
            " [-0.65874416 -2.07657332 -1.90652448 -0.37242428 -0.4852155  -1.76898989]\n",
            " ...\n",
            " [ 1.12329206 -1.26112705 -1.18600873  2.81721597  1.70343448 -0.53208757]\n",
            " [-0.06473208  0.91339632 -0.46549297 -0.37242428 -0.4852155   0.45743429]\n",
            " [-0.9557502   0.36976548  0.25502279 -0.61544449  2.43298447  0.21005383]]\n"
          ]
        }
      ],
      "source": [
        "print(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "SEiM9qwRF6G_"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRZLBewtF8-b",
        "outputId": "4177461b-f947-463f-c96c-dbac46ee286a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.89\n",
            "F1 Score: 0.89\n"
          ]
        }
      ],
      "source": [
        "# Create and train the Random Forest model\n",
        "model = RandomForestClassifier(n_estimators=200)\n",
        "\n",
        "# Tune the hyperparameters of the model using GridSearchCV\n",
        "param_grid = {'max_depth': [5, 10, 20], 'min_samples_split': [2, 5, 10]}\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Use the best parameters from the grid search to train the model\n",
        "model = grid_search.best_estimator_\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print(f'F1 Score: {f1:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.80724718 -1.26112705 -0.82575085  0.69078914  1.70343448 -0.53208757]\n"
          ]
        }
      ],
      "source": [
        "#Testing the model using a random sample\n",
        "import numpy\n",
        "arr = [-0.80724718, -1.26112705, -0.82575085,  0.69078914,  1.70343448, -0.53208757]\n",
        "testData = numpy.array(arr)\n",
        "print(testData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['high risk']\n"
          ]
        }
      ],
      "source": [
        "#Necessary to reshape the input sample\n",
        "prediction = model.predict(testData.reshape(1,-1))\n",
        "print(prediction)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b>DO NOT RUN THIS CELL UNLESS YOU WANT TO UPDATE THE MODEL. EVEN IF YOU DO, DO NOT PUSH IT TO THE REPO</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5oh-FwKpOAp2"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "import pickle\n",
        "with open('model.pkl', 'wb') as file:\n",
        "  pickle.dump(model, file)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "afb734500600fd355917ca529030176ea0ca205570884b88f2f6f7d791fd3fbe"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
