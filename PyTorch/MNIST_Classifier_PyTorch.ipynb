{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "from torchvision.utils import save_image\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "C4908mQNCEFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTData(Dataset):\n",
        "  \n",
        "  # Dataset Initialization Parameters\n",
        "  def __init__(self, dataset=\"train\"):\n",
        "    if dataset == \"train\":\n",
        "      dataFile = open('sample_data/mnist_train_small.csv')\n",
        "    if dataset ==\"test\":\n",
        "      dataFile = open('sample_data/mnist_test.csv')\n",
        "    self.data = dataFile.readlines()\n",
        "    dataFile.close()\n",
        "    print(dataset,'set has ', len(self.data),' samples')\n",
        "  \n",
        "  # Fetching data from specific index\n",
        "  def __getitem__(self, idx):\n",
        "    target = torch.LongTensor([int(self.data[idx][0])])\n",
        "    image = torch.Tensor([float(i) for i in self.data[idx][2:].split(',')])\n",
        "    save_image(image.reshape(28,28),'img.png')\n",
        "    return(image, target)\n",
        "  \n",
        "  # Calculating the length of the dataset\n",
        "  def __len__(self):\n",
        "    return(len(self.data))\n",
        "\n",
        "# Creating DataLoaders\n",
        "trainLoader = DataLoader(MNISTData(\"train\"),batch_size=4)\n",
        "testLoader = DataLoader(MNISTData(\"test\"),batch_size=4)"
      ],
      "metadata": {
        "id": "0BvISzQCgUe1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78396b48-0dac-40bb-f57f-3c7507adba5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set has  20000  samples\n",
            "test set has  10000  samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class MyNeuralNetwork(nn.Module):\n",
        "\n",
        "# Defining Layers of the Model\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer1 = nn.Linear(784, 400)\n",
        "    self.layer2 = nn.Linear(400,100)\n",
        "    self.outputLayer = nn.Linear(100, 10)\n",
        "\n",
        "\n",
        "# Defining the operations regarding forward pass\n",
        "  def forward(self, x):\n",
        "    layer1Out = torch.sigmoid(self.layer1(x))\n",
        "    layer2Out = torch.sigmoid(self.layer2(layer1Out))\n",
        "    output = self.outputLayer(layer2Out)\n",
        "    return (torch.softmax(output, 0))\n",
        "\n"
      ],
      "metadata": {
        "id": "D0LwP1WXRYZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating instance of the model, .cuda() ports the model to the GPU Memory\n",
        "myModel = MyNeuralNetwork().cuda()\n",
        "print(myModel)\n",
        "\n",
        "# Defining Loss function and optimization algorithm\n",
        "lossFn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(myModel.parameters(), lr = 1e-2)\n",
        "\n",
        "# Epochs define the number of times the model will go over the entire data\n",
        "for epoch in range(20):                         \n",
        "  trainloss = 0.0\n",
        "\n",
        "  # Using the dataLoader to fetch batches of training samples\n",
        "  for image, target in trainLoader:\n",
        "    \n",
        "    image, target = image.cuda(), target.cuda()           # Porting the data to the GPU\n",
        "    optimizer.zero_grad()                                 # Resetting Gradients\n",
        "    output = myModel(image)                               # Forward Pass\n",
        "    loss = lossFn(output, target.squeeze())               # Calculate Loss  4x10,  4\n",
        "    loss.backward()                                       # Backward Pass\n",
        "    optimizer.step()                                      # Weight Update\n",
        "       \n",
        "\n",
        "    #Tracking the training loss\n",
        "    trainloss+=loss.item()              \n",
        "  \n",
        "  testloss = 0.0\n",
        "  testcorrect = 0\n",
        "  testtotal = 0\n",
        "\n",
        "  # Using the dataLoader to fetch batches of test samples\n",
        "  for image, target in testLoader:\n",
        "    \n",
        "    image, target = image.cuda(), target.cuda()           # Porting the data to the GPU\n",
        "    output = myModel(image)                               # Forward Pass\n",
        "    loss = lossFn(output, target.squeeze())               # Calculate Loss\n",
        "    \n",
        "    # Tracking the Test Loss\n",
        "    testloss+=loss.item()\n",
        "    \n",
        "    # Calculating Accuracy\n",
        "    _, predicted = torch.max(output.data, 1)              # Find model predictions for the test samples\n",
        "    testtotal += target.size(0)                           # Total no. of samples\n",
        "    testcorrect += (predicted == target).sum().item()     # No. of correctly classified samples\n",
        "  \n",
        "  # Printing results every epoch\n",
        "  print('Train Loss -',trainloss/len(trainLoader),\n",
        "        '- Test Loss -',testloss/len(testLoader),\n",
        "        '- Test Accuracy -',100 * testcorrect // testtotal)"
      ],
      "metadata": {
        "id": "yfz7rV9xcK6V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c576616a-8a96-4732-9e36-2d962d968fb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyNeuralNetwork(\n",
            "  (layer1): Linear(in_features=784, out_features=400, bias=True)\n",
            "  (layer2): Linear(in_features=400, out_features=100, bias=True)\n",
            "  (outputLayer): Linear(in_features=100, out_features=10, bias=True)\n",
            ")\n",
            "Train Loss - 2.1602890765190126 - Test Loss - 1.9678018528938293 - Test Accuracy - 76\n",
            "Train Loss - 1.9023548152685166 - Test Loss - 1.8372609119415284 - Test Accuracy - 83\n",
            "Train Loss - 1.834674150800705 - Test Loss - 1.8035554067134858 - Test Accuracy - 86\n",
            "Train Loss - 1.8122262165546417 - Test Loss - 1.7888120867729187 - Test Accuracy - 87\n",
            "Train Loss - 1.799916297030449 - Test Loss - 1.7788540749549866 - Test Accuracy - 89\n",
            "Train Loss - 1.7920144342660904 - Test Loss - 1.7743776111602783 - Test Accuracy - 89\n",
            "Train Loss - 1.7858805072784423 - Test Loss - 1.7692764681339264 - Test Accuracy - 90\n",
            "Train Loss - 1.7818806226968764 - Test Loss - 1.7662573014259337 - Test Accuracy - 91\n",
            "Train Loss - 1.778966247010231 - Test Loss - 1.7630080564975739 - Test Accuracy - 91\n",
            "Train Loss - 1.7759170220851899 - Test Loss - 1.760960708141327 - Test Accuracy - 92\n",
            "Train Loss - 1.7735410956144333 - Test Loss - 1.7588236351013184 - Test Accuracy - 92\n",
            "Train Loss - 1.7715009115695954 - Test Loss - 1.7571571517944335 - Test Accuracy - 92\n",
            "Train Loss - 1.7692578813314437 - Test Loss - 1.7565797944068908 - Test Accuracy - 92\n",
            "Train Loss - 1.7673697434902191 - Test Loss - 1.7543078207015992 - Test Accuracy - 93\n",
            "Train Loss - 1.7667492926120758 - Test Loss - 1.753519837808609 - Test Accuracy - 93\n",
            "Train Loss - 1.7650382352113725 - Test Loss - 1.752205648612976 - Test Accuracy - 94\n",
            "Train Loss - 1.762829877781868 - Test Loss - 1.7501718376636506 - Test Accuracy - 94\n",
            "Train Loss - 1.761971930027008 - Test Loss - 1.7501559951782226 - Test Accuracy - 94\n",
            "Train Loss - 1.761103843808174 - Test Loss - 1.7484470488071442 - Test Accuracy - 94\n",
            "Train Loss - 1.7605762658834458 - Test Loss - 1.7489641013622284 - Test Accuracy - 94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4GIqLgdGipIa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}